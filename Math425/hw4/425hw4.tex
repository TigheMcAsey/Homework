\documentclass[10.5pt]{article}
\usepackage{amsmath, amsfonts, amssymb,amsthm}
\usepackage[includeheadfoot]{geometry} % For page dimensions
\usepackage{fancyhdr}
\usepackage{enumerate} % For custom lists

\fancyhf{}
\lhead{Math 425hw4}
\rhead{Tighe McAsey - 37499480}
\pagestyle{fancy}

% Page dimensions
\geometry{a4paper, margin=1in}

\theoremstyle{definition}
\newtheorem{pb}{}

% Commands:

\newcommand{\set}[1]{\{#1\}}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\norm}[1]{\lvert\lvert#1\rvert\rvert}
\newcommand{\gen}[1]{\langle #1 \rangle}
\newcommand{\tand}{\text{ and }}
\newcommand{\tor}{\text{ or }}
\newcommand{\vp}{\varphi}
\newcommand{\R}{\text{Re}}
\newcommand{\I}{\text{Im}}

\begin{document}
    \begin{pb}
        \textbf{(a)} We first need to show the homomorphism property, to do so apply the chain rule, where we note that \(C_g(e) = e\) for all \(g\). Then
        \begin{align*}
            d (C_{g_1} C_{g_2})_e (x) = d(C_{g_1})_{C_{g_2}(e)} \circ d(C_{g_2})_e (x) = d(C_{g_1})_{e} \circ d(C_{g_2})_e (x) \\
        \end{align*}
        This also implies that the pushforward of the identity is the identity (by swapping either of \(g_1 \tor g_2\) for the identity).

        Smoothness follows from lie group multiplication being smooth, and the pushforward of a smooth map is smooth.

        \textbf{(b)} We know that \(e^{tX}\) is a path satisfying \(e^{tX} \vert_{t=0} = \mathbf{1_n} \tand \frac{d}{dt} e^{tX} \vert_{t=0} = X\). Then for \(g \in G\) we have
        \begin{align*}
            d(C_g)_e = \frac{d}{dt}\vert_{t=0} C_g(e^{tX}) = \frac{d}{dt}\vert_{t=0} e^{tgXg^{-1}} =  gXg^{-1}
        \end{align*}

        \textbf{(c)} We take the path \(\gamma(t) = e^{tX}\), which satisfies \(\gamma(0) = \mathbf{1_n}, \; \gamma'(0) = X\), then
        \begin{align*}
            d(Ad)_e(x)(y) &= \frac{d}{dt}\vert_{t=0} \text{Ad}_\gamma(t)(y) = \frac{d}{dt}\vert_{t=0} \gamma(t)y\gamma^{-1}(t) \\ &= \frac{d}{dt}\vert_{t=0}e^{tX}ye^{-tX}
            = \left(\frac{d}{dt}\vert_{t=0} e^{tX}y\right)\mathbf{1_n} + \mathbf{1_n}y \frac{d}{dt}\vert_{t=0} e^{-tX} \\
            &= Xy - yX = [X,y]
        \end{align*}

    \end{pb}
    \begin{pb}
        \textbf{(a)} We can simply compute the product of basis elements, first note that \(\sigma_i^2 = \mathbf{1}\), and that 
        \begin{align*}
            \sigma_1\sigma_2 = i\sigma_3 = -\sigma_2\sigma_1 \\
            \sigma_1\sigma_3 = -i\sigma_2 = -\sigma_3\sigma_1 \\
            \sigma_2\sigma_3 = i\sigma_1 = -\sigma_3\sigma_2
        \end{align*}
        Since each of \(\sigma_i\) are of trace 0, we get for some \(c_i\) which turn out not to matter
        \begin{align*}
            \text{Tr}(xy) &= \text{Tr}((x_1\sigma_1 + x_2\sigma_2 + x_3\sigma_3)(y_1\sigma_1 + y_2\sigma_2 + y_3\sigma_3)) \\
            &= \text{Tr}(\mathbf{1}(x_1y_1 + x_2y_2 + x_3y_3)) + \text{Tr}(\sum_1^3 c_i \sigma_i) \\
            &= \sum_1^3 2x_iy_i + \sum_1^3 c_i \text{Tr}(\sigma_i) = 2\sum_1^3 x_iy_i
        \end{align*}
        So we may conclude that \[\begin{pmatrix} x_1 \\ x_2 \\ x_3\end{pmatrix}\cdot \begin{pmatrix} y_1 \\ y_2 \\ y_3\end{pmatrix} = \frac12 \text{Tr}xy\]

        We already verified in 1a that \(\varphi: g \mapsto \text{Ad}(g)\) is a Lie group representation, i.e. This map satisfies the homomorphism property. It remains to show that
        \(\varphi\) maps into \(\text{SO}(3)\). Note that orthogonal matrices are characterized by preservation of inner products, i.e. \(M\) orthogonal iff for any \(x,y\) we have
        \(\gen{Mx,My} = \gen{x,y}\). To show that \(\varphi(g)\) satisfies this property see the following computation:
        \begin{align*}
            \gen{\varphi_g(x),\varphi_g(y)} = \gen{gxg^{-1},gyg^{-1}} = \frac{1}{2}\text{Tr}(gxyg^{-1}) = \frac{1}{2}\text{Tr}(xy) = \gen{x,y}
        \end{align*}
        Here we use the fact that eigenvalues and hence trace are invarient under conjugation. Finally, we note that \(\varphi(\mathbf{1}) = \mathbf{1}\), and for any \(g\),
        \(\varphi(g)\) is orthogonal implies that \(\det \varphi(g) = \pm 1\). Note that the continuous map
        \begin{align*}
            \text{SU}(2) \to S^3 \\
            \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix} \mapsto (\text{Re}(u),\text{Im}(u),\text{Re}(v),\text{Im}(v))
        \end{align*}
        is a homeomorphism (closed map lemma by SU(2) compact and \(S^3\) Hausdorff). Since \(S^3\) is connected, this implies connectedness of \(\text{SU}(2)\).
        It follows that since \(\varphi\) is continuous, that \(\varphi(\text{SU}(2))\) is also connected. If we were to have
        \[\varphi(\text{SU}(2)) \cap \set{X \in O^3 \vert \det X = -1} \neq \emptyset \tand \varphi(\text{SU}(2)) \cap \set{X \in O^3 \vert \det X = 1} \neq \emptyset\]
        then this would contradict connectedness of \(\varphi(\text{SU}(2))\), and since \(\mathbf{1} \in \varphi(\text{SU}(2)) \cap \text{SO}(3) \neq \emptyset\) we must have
        \(\varphi(\text{SU}(2)) \subset \text{SO}(3)\).

        \textbf{(b)} write \(g := \begin{bmatrix} e^{-i\theta} & 0 \\ 0 & e^{i\theta} \end{bmatrix}\). Then
        \begin{align*}
            &g\sigma_1g^{-1} = \begin{bmatrix} e^{-i\theta} & 0 \\ 0 & e^{i\theta} \end{bmatrix}\begin{bmatrix} 0 & e^{-i\theta} \\ e^{i\theta} & 0 \end{bmatrix}
            = \begin{bmatrix} 0 & e^{-2i\theta} \\  e^{2i\theta} & 0 \end{bmatrix} = \cos2\theta \sigma_1 + \sin2\theta \sigma_2 \\
            &g\sigma_2g^{-1} = \begin{bmatrix} e^{-i\theta} & 0 \\ 0 & e^{i\theta} \end{bmatrix}\begin{bmatrix} 0 & -ie^{-i\theta} \\ ie^{i\theta} & 0 \end{bmatrix}
            = \begin{bmatrix} 0 & -ie^{-2i\theta} \\  ie^{2i\theta} & 0 \end{bmatrix} = -\sin2\theta \sigma_1 + \cos 2\theta \sigma_2\\
            &g\sigma_3g^{-1} = \begin{bmatrix} e^{-i\theta} & 0 \\ 0 & e^{i\theta} \end{bmatrix}\begin{bmatrix} e^{i\theta} & 0 \\ 0 & -e^{-i\theta} \end{bmatrix} = \sigma_3
        \end{align*}
        So that \(\varphi(g)\) acts as
        \begin{align*}
            \begin{bmatrix} \cos2\theta & -\sin2\theta & 0 \\ \sin2\theta & \cos2\theta & 0 \\ 0 & 0 & 1 \end{bmatrix}
        \end{align*}
        on the basis \(\set{\sigma_i}_1^3\)

        \textbf{(c)} First notice that the pushforward of conjugation on a single Pauli matrix is just the bracket as in question 1c (\(\text{ad}_x(y)\)). Computing this we get (see my mult table in 2a)
        \begin{align*}
            &[\sigma_\alpha/2i,\sigma_j] = 0 &i=j \\
            &[\sigma_1/2i,\sigma_2] = \frac{1}{2i}(i\sigma_3 - (-i\sigma_3)) = \sigma_3 \\
            &[\sigma_1/2i,\sigma_3] = \frac{1}{2i}(-i\sigma_2 - i\sigma_2) = -\sigma_2 \\
            &[\sigma_2/2i,\sigma_1] = \frac{1}{2i}(-i \sigma_3 - \sigma_3) = -\sigma_3 \\
            &[\sigma_2/2i,\sigma_3] = \frac{1}{2i}(i \sigma_1 - (-i\sigma_1)) = \sigma_1 \\
            &[\sigma_3/2i,\sigma_1] = \frac{1}{2i}(i\sigma_2 + i\sigma_2) = \sigma_2 \\
            &[\sigma_3/2i,\sigma_2] = \frac{1}{2i}(-i \sigma_1 - i \sigma_1) = -\sigma_1
        \end{align*}
        Using this rule, we can write the matrices.
        \begin{align*}
            E_1 = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & 1 & 0 \end{bmatrix} \quad E_2 = \begin{bmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ -1 & 0 & 0 \end{bmatrix} \quad 
            E_3 = \begin{bmatrix} 0 & -1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}
        \end{align*}

        \textbf{(d)} Given \(g = \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix}\), compute \(g^{-1} = \begin{bmatrix} \overline{u} & \overline{v} \\ -v & u \end{bmatrix}\).
        Then we compute the action of \(g\) on each \(\sigma_i\),
        \begin{align*}
            g \sigma_1 g^{-1} = \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix}\begin{bmatrix} -v & u \\ \overline{u} & \overline{v} \end{bmatrix} = 
            \begin{bmatrix} -2\text{Re}(uv) & u^2 - \overline{v}^2 \\ \overline{u^2 - \overline{v^2}} & 2\text{Re}(uv) \end{bmatrix} = -2\text{Re}(uv) \sigma_3 + c \sigma_1 + d \sigma_2
        \end{align*}
        Where \(c = \text{Re}(u)^2 - \text{Re}(v)^2 - \text{Im}(u)^2 + \text{Im}(v)^2 \tand d = -2(\text{Re}(u)\text{Im}(u) + \text{Re}(v)\text{Im}(v))\).

        \begin{align*}
            g \sigma_3 g^{-1} &= \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix}\begin{bmatrix} \overline{u} & \overline{v} \\ v & -u \end{bmatrix} = 
            \begin{bmatrix} \abs{u}^2 - \abs{v^2} & 2u \overline{v} \\ \overline{2u \overline{v}} & \abs{v}^2 - \abs{u}^2 \end{bmatrix} \\
            &= (\abs{u^2} - \abs{v^2})\sigma_3 + 2(\text{Re}(u)\text{Re}(v) + \text{Im}(u)\text{Im}(v))\sigma_1 + 2(\text{Re}(u)\text{Im}(v) - \text{Im}(u)\text{Re}(v))\sigma_2
        \end{align*}

        And lastly,
        \begin{align*}
            g \sigma_2 g^{-1} = \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix}\begin{bmatrix} iv & -iu \\ i \overline{u} & i \overline{v} \end{bmatrix}
            = \begin{bmatrix} -2\text{Im}(uv) & s+ir \\ s-ir &  2 \text{Im}(uv) \end{bmatrix} = s\sigma_1 + r\sigma_2 - 2\text{Im}(uv) \sigma_3
        \end{align*}
        Where \(r = (\text{Re}(u)^2 - \text{Im}(u)^2 + \text{Re}(v)^2 - \text{Im}(v)^2) \tand s = 2(\text{Re}(u)\text{Im}(u) - \text{Re}(v)\text{Im}(v))\).

        Using this we can write down the matrix representation of \(\varphi(g)\), being
        \begin{align*}
            \varphi(g) = \begin{bmatrix} 
                c & s & 2(\text{Re}(u)\text{Re}(v) + \text{Im}(u)\text{Im}(v)) \\ 
                d & r & 2(\text{Re}(u)\text{Im}(v) - \text{Im}(u)\text{Re}(v)) \\ 
                -2\text{Re}(uv) & -2\text{Im}(uv) & (\abs{u^2} - \abs{v^2}) 
            \end{bmatrix}
        \end{align*}
        For \(g\) as above, and \(c,d,r,s\) defined above.

        \textbf{(e)} To compute the kernel, we use the form of the amtrix computed in part (d). Assume that \(g \in \ker \varphi\), 
        then using the diagonal entries, (writing \(\varphi(g) = (\varphi_{i,j})_{i,j}\)). We get the relation
        \begin{align*}
            4\text{Re}(u)^2 = \sum_1^3 \varphi_{i,i} + \abs{u}^2 + \abs{v}^2 = 4 \iff \text{Re}(u) = \pm 1 \iff u = \pm 1
        \end{align*}
        this of course also implies that \(v = 0\), plugging in these values for \(u\) in we see that both are solutions, so that 
        \(\ker \varphi = \mathbf{1}, - \mathbf{1}\).

        To show surjectivity, note that since \(\varphi\) is 2:1, with kernel \(\pm \mathbf{1}\), we have that \(\varphi(g) = \varphi(h) \iff h = -g\), given this
        if \(U \subset \text{SU}(2)\), such that \(U \cap -U = \emptyset\), then \(\varphi\vert_U\) is injective. As before, write a general element \(g \in \text{SU}(2)\) as 
        \(g = \begin{bmatrix} u & -\overline{v} \\ v & \overline{u} \end{bmatrix}\), the projection map \(g \mapsto \text{Re}(u)\) is continuous, so that 
        \(U := \set{g \in \text{SU}(2) \vert \text{Re}(u) \geq \frac{1}{2}}\) is closed, and \(U \supset V := \set{g \in \text{SU}(2) \vert \text{Re}(u) > \frac{1}{2}}\) is open.
        Furthermore, we have \(U \cap -U = \emptyset\), since for any \(g \in -U\), \(\text{Re}(u) \leq -\frac{1}{2}\). This suffices to show that \(\varphi\vert_U\) is injective.
        Now since \(U \subset \text{SU}(2)\) is a closed subset of a compact set (hence compact), and SO(3) is hausdorff (this is clear since it can be identified as a subspace of \(\mathbb{R}^9\))
        we can conclude by the closed map lemma that \(\varphi\vert_U\) is homeomorphic onto its image, hence is an open map. This implies that \(\varphi(V) = \varphi\vert_U (V)\) is open in
        \(\text{SO}(3)\), and in particular \(\mathbf{1} \in V\) implies that \(\mathbf{1} \in \varphi(V)\) is an open set in SO(3) mapped onto by \(\varphi\) containing \(\mathbf{1}\).
        Then we have that \(\vp(\text{SU}(2)) \supset \gen{\varphi(V)} = \text{SO}(3)\) proving that the map is onto as desired.
    \end{pb}

    % consider \(\varphi^{-1}: \varphi(g) \mapsto \set{g,-g}\). 
    %     Then since \(\varphi\) is continuous, we can choose some neighborhood \(V\) of \(\mathbf{1}\) small enough that
    %     \(\varphi^{-1}(V) = U \sqcup -U\), where \(1 \in U \tand -1 \in -U\). Then we can define 
    %     \begin{align*}
    %         &\psi^+: V \mapsto U & \psi^+ (h) = \vp^{-1}(h) \cap U \\
    %         &\psi^-: V \mapsto U & \psi^+ (h) = \vp^{-1}(h) \cap -U
    %     \end{align*}
    %     We need only check that these define continuous maps, which suffices to show that \(\varphi\) is open.
    %     Let \(\varphi \in \text{SO}(3)\), and write \(\varphi = (\varphi_{i,j})_{i,j}\) from the form of the matrix in part (d), we get that if \(\varphi = \varphi(g)\), then we can use the relations to
    %     define the piecewise inverse.
    %     \begin{align*}
    %         4\text{Re}(u)^2 = 1 + \sum_1^3 \varphi_{i,i} \implies \text{Re}(u) = \pm\sqrt{\frac{1 + \sum_1^3 \varphi_{i,i}}{4}} \\
    %         \varphi_{3,1} - \varphi_{1,3} = 4 \text{Re}(u)\text{Re}(v) \implies \text{Re}(v) = \frac{\varphi_{3,1} - \varphi_{1,3}}{\pm2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} \\
    %         \varphi_{2,1} - \varphi_{1,2} = 4\text{Re}(u)\text{Im}(u) \implies \text{Im}(u) = \frac{\varphi_{2,1} - \varphi_{1,2}}{\pm2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} \\
    %         \varphi_{2,3} + \varphi_{3,2} = 4\text{Re}(u){Im}(v) \implies \text{Im}(v) = \frac{\varphi_{2,3} + \varphi_{3,2}}{\pm2\sqrt{1 + \sum_1^3 \varphi_{i,i}}}
    %     \end{align*}
    %     Hence on \(V\) we have 
    %     \begin{align*}
    %         \psi^+: (\varphi_{i,j})_{i,j} \mapsto \begin{bmatrix} \sqrt{\frac{1 + \sum_1^3 \varphi_{i,i}}{4}} + \frac{\varphi_{2,1} - \varphi_{1,2}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}}
    %             & -\frac{\varphi_{3,1} - \varphi_{1,3}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} + \frac{\varphi_{2,3} + \varphi_{3,2}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}}\\ 
    %             \frac{\varphi_{3,1} - \varphi_{1,3}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} + \frac{\varphi_{2,3} + \varphi_{3,2}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} & 
    %             \sqrt{\frac{1 + \sum_1^3 \varphi_{i,i}}{4}} - \frac{\varphi_{2,1} - \varphi_{1,2}}{2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} \end{bmatrix}\\
    %         \psi^-: (\varphi_{i,j})_{i,j} \mapsto \begin{bmatrix} -\sqrt{\frac{1 + \sum_1^3 \varphi_{i,i}}{4}} + \frac{\varphi_{2,1} - \varphi_{1,2}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}}
    %             & -\frac{\varphi_{3,1} - \varphi_{1,3}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} + \frac{\varphi_{2,3} + \varphi_{3,2}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}}\\ 
    %             \frac{\varphi_{3,1} - \varphi_{1,3}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} + \frac{\varphi_{2,3} + \varphi_{3,2}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} & 
    %             -\sqrt{\frac{1 + \sum_1^3 \varphi_{i,i}}{4}} - \frac{\varphi_{2,1} - \varphi_{1,2}}{-2\sqrt{1 + \sum_1^3 \varphi_{i,i}}} \end{bmatrix} = -\psi^+ ((\varphi_{i,j})_{i,j})
    %     \end{align*}
    %     Are continuous, and hence as above we have that \(\varphi\vert_{U \sqcup -U}\) is open, so that \(\mathbf{1} \in \varphi(U \sqcup -U)\) which is open. Since SO(3) is connected,
    %     we use the fact that an open set of the identity in a lie group generates the whole connected component containing the identity in this case, \(\gen{\varphi(U \sqcup -U)} = \text{SO}(3)\).
\end{document}